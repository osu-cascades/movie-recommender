{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 406 Movie Recommender\n",
    "\n",
    "### Ryder McDowell\n",
    "\n",
    "#### OSU Cascades\n",
    "\n",
    "...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 4808k  100 4808k    0     0  2526k      0  0:00:01  0:00:01 --:--:-- 2525k\n",
      "Archive:  ml-100k.zip\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    }
   ],
   "source": [
    "!curl -O http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -o ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "1\t1\t5\t874965758\n",
      "1\t2\t3\t876893171\n",
      "1\t3\t4\t878542960\n",
      "1\t4\t3\t876893119\n",
      "1\t5\t3\t889751712\n",
      "1\t6\t5\t887431973\n",
      "1\t7\t4\t875071561\n",
      "1\t8\t1\t875072484\n",
      "1\t9\t5\t878543541\n",
      "1\t10\t3\t875693118\n",
      "\n",
      "Testing Data:\n",
      "1\t20\t4\t887431883\n",
      "1\t33\t4\t878542699\n",
      "1\t61\t4\t878542420\n",
      "1\t117\t3\t874965739\n",
      "1\t155\t2\t878542201\n",
      "1\t160\t4\t875072547\n",
      "1\t171\t5\t889751711\n",
      "1\t189\t3\t888732928\n",
      "1\t202\t5\t875072442\n",
      "1\t265\t4\t878542441\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data:\")\n",
    "!head -10 ./ml-100k/ua.base\n",
    "\n",
    "print(\"\\nTesting Data:\")\n",
    "!head -10 ./ml-100k/ua.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, io, json\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(csv_reader):\n",
    "    samples = []\n",
    "    for userId,movieId,rating,timestamp in csv_reader:\n",
    "        samples.append({\n",
    "            'userId': userId,\n",
    "            'movieId': movieId,\n",
    "            'rating': rating,\n",
    "            'timestamp': timestamp\n",
    "        })\n",
    "        \n",
    "    return samples\n",
    "    \n",
    "    \n",
    "def get_maximums(samples):\n",
    "    users = []\n",
    "    movies = []\n",
    "    for sample in samples:\n",
    "        users.append(int(sample['userId']))\n",
    "        movies.append(int(sample['movieId']))\n",
    "\n",
    "    max_user_id = max(users)\n",
    "    max_movie_id = max(movies)\n",
    "    \n",
    "    return max_user_id, max_movie_id\n",
    "\n",
    "\n",
    "def get_matrix_shape(max_user_id, max_movie_id, samples):\n",
    "    total_samples = len(samples)\n",
    "    total_features = max_user_id + max_movie_id\n",
    "\n",
    "    return total_samples, total_features\n",
    "\n",
    "\n",
    "def fill_data(data, labels, samples):\n",
    "    row = 0\n",
    "        \n",
    "    # Build matrix and labels\n",
    "    for sample in samples:\n",
    "\n",
    "        # One hot-encode userId and movieId at row\n",
    "        user_index = int(sample['userId']) - 1\n",
    "        movie_index = 943 + int(sample['movieId']) - 1    #!!\n",
    "\n",
    "        data[row, user_index] = 1\n",
    "        data[row, movie_index] = 1\n",
    "\n",
    "        # Append binary to labels for whether user \"enjoyed\" movie\n",
    "        if int(sample['rating']) >= 4:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "\n",
    "        row = row + 1\n",
    "\n",
    "    # Convert labels list to float 32\n",
    "    labels = np.array(labels).astype('float32')\n",
    "    \n",
    "    return data, labels\n",
    "    \n",
    "\n",
    "def load_dataset(training_data_file_path, testing_data_file_path):\n",
    "    # Training Data\n",
    "    with open(training_data_file_path, 'r') as file:\n",
    "        csv_reader = csv.reader(file, delimiter='\\t')\n",
    "        \n",
    "        # Get all training samples in form of [{}, {}, ...]\n",
    "        training_samples = get_samples(csv_reader)\n",
    "        \n",
    "        # Get maximum number of users and movies\n",
    "        max_user_id, max_movie_id = get_maximums(training_samples)\n",
    "        \n",
    "        # Get shape of training matrix\n",
    "        training_matrix_shape = get_matrix_shape(max_user_id, max_movie_id, training_samples)\n",
    "        \n",
    "        # Initialize training data and labels structures\n",
    "        training_data = lil_matrix(training_matrix_shape).astype('float32')\n",
    "        training_labels = []\n",
    "\n",
    "        # Fill training data and labels structures with sample training data \n",
    "        training_data, training_labels = fill_data(training_data, training_labels, training_samples)\n",
    "        \n",
    "    # Testing Data\n",
    "    with open(testing_data_file_path, 'r') as file:\n",
    "        csv_reader = csv.reader(file, delimiter='\\t')\n",
    "        \n",
    "        # Get all testing samples in form of [{}, {}, ...]\n",
    "        testing_samples = get_samples(csv_reader)\n",
    "        \n",
    "        #Get shape of testing matrix\n",
    "        testing_matrix_shape = get_matrix_shape(max_user_id, max_movie_id, testing_samples)\n",
    "        \n",
    "        # Initialize testing data and labels structures\n",
    "        testing_data = lil_matrix(testing_matrix_shape).astype('float32')\n",
    "        testing_labels = []\n",
    "        \n",
    "        # Fill testing data and labels structurs with sample testing data\n",
    "        testing_data, testing_labels = fill_data(testing_data, testing_labels, testing_samples)\n",
    "        \n",
    "    \n",
    "    \n",
    "    return (training_data, training_labels), (testing_data, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_file_path = './ml-100k/ua.base'\n",
    "testing_data_file_path = './ml-100k/ua.test'\n",
    "\n",
    "(training_data, training_labels), (testing_data, testing_labels) = load_dataset(training_data_file_path, testing_data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ratings, Features)\n",
      "(90570, 2625)\n",
      "(90570,)\n",
      "(9430, 2625)\n",
      "(9430,)\n"
     ]
    }
   ],
   "source": [
    "print(\"(Ratings, Features)\")\n",
    "print(training_data.shape)\n",
    "print(training_labels.shape)\n",
    "\n",
    "print(testing_data.shape)\n",
    "print(testing_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6)\t1.0\n",
      "  (0, 1493)\t1.0\n",
      "  (1, 6)\t1.0\n",
      "  (1, 1494)\t1.0\n",
      "  (2, 6)\t1.0\n",
      "  (2, 1495)\t1.0\n",
      "  (3, 6)\t1.0\n",
      "  (3, 1496)\t1.0\n",
      "  (4, 6)\t1.0\n",
      "  (4, 1497)\t1.0\n",
      "[0. 1. 0. 0. 1.]\n",
      "  (0, 6)\t1.0\n",
      "  (0, 1493)\t1.0\n",
      "  (1, 6)\t1.0\n",
      "  (1, 1494)\t1.0\n",
      "  (2, 6)\t1.0\n",
      "  (2, 1495)\t1.0\n",
      "  (3, 6)\t1.0\n",
      "  (3, 1496)\t1.0\n",
      "  (4, 6)\t1.0\n",
      "  (4, 1497)\t1.0\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(training_data[1000:1005])\n",
    "print(training_labels[1000:1005])\n",
    "\n",
    "print(training_data[1000:1005])\n",
    "print(testing_labels[1000:1005])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.10% Movies Rated Above 3 in Training Data\n",
      "58.00% Movies Rated Above 3 in Testing Data\n"
     ]
    }
   ],
   "source": [
    "print(\"{:0.2f}% Movies Rated Above 3 in Training Data\".format(np.count_nonzero(training_labels) / training_data.shape[0] * 100))\n",
    "print(\"{:0.2f}% Movies Rated Above 3 in Testing Data\".format(np.count_nonzero(testing_labels) / testing_data.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.99924% Sparse\n"
     ]
    }
   ],
   "source": [
    "encoded_values = training_data.shape[0] * 2\n",
    "total_values = training_data.shape[0] * training_data.shape[1]\n",
    "\n",
    "print(\"{:0.5f}% Sparse\".format(100 - (encoded_values / total_values)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
